---
title: "Piyakorn(Mona) Munegan StudentID: 46318461"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
surg=read.table('data/surg.dat', header = TRUE)
kml=read.table('data/kml.dat', header = TRUE)
```

```{r load-packages, include=FALSE}
library(ggplot2)
```

# Assignment Semester 1
## Question 1

A medical research team wants to investigate the survival time of patients that have a particular type of liver
operation as part of their treatment. For each patient in the study, the following variables were recorded:

| || |
| --- | --- |
| blood | Blood clotting Index |
| prognosis | Prognosis Index |
| enzyme | Enzyme function Index |
| liver | Liver function Index |
| age | Age of the patient, in years |
| gender | Gender of the patient, (Male of Female) |
| survival | Survival time of the patient after surgery (in days) |


a. Produce a scatterplot of the data and comment on the features of the data and possible relationships
between the response and predictors and relationships between the predictors themselves.

```{r corr, echo=FALSE}
surg.cor <- data.frame(surg)
surg.cor$gender <- NULL
```

&nbsp;

```{r scatterplot, echo=FALSE}
plot(surg.cor)
```

\quad There are positive moderate correlation between survival and enzyme and liver. Slight correlation between survival and prognosis.
\
&nbsp;
\
&nbsp;
Why it is necessary to remove the gender variable to compute the correlation matrix?
\
&nbsp;
\quad Because the gender variable is a categorical variables. To compute the correlation matrix, every variables must be numeric.

&nbsp;
b. Compute the correlation matrix of the dataset and comment.
&nbsp;
```{r corrmatrix, echo=FALSE}
corr <- round(cor(surg.cor), 2)
corr
#ggcorrplot(corr, outline.col = "white", lab = TRUE, lab_size = 4, tl.cex=12, legend.title = "Correlation")
```
\
&nbsp;
\quad The correlation matrix shows that there are moderate correlation between survival and liver(0.67) and enzyme(0.58).
Low correlation between survival and blood(0.35) and prognosis(0.42). The correlation between survival and age is -0.12, 
which is close to 0, indicates that no linear relationship between these variables.
\
&nbsp;
\
&nbsp;
c. Fit a model using all the predictors to explain the survival response.Conduct an F-test for the overall
regression i.e. is there any relationship between the response and the predictors. In your answer:

```{r c1, echo=FALSE}
surg.new <- data.frame(surg)
#Transforming Gender to numerical variable
surg.new$gender[surg$gender=="M"] <- 1
surg.new$gender[surg$gender=="F"] <- 0
surg.new$gender <- as.integer(surg.new$gender)
```

```{r c2, echo=FALSE}
#Fitting linear model with original data
surg.lm1 = lm(survival ~ blood  + prognosis  + enzyme  + liver + age + gender, data = surg.new)
par(mfrow = c(1, 2))
plot(surg.lm1, which=1:2)
```
\
&nbsp;
\quad There is a significant pattern in the residuals vs fitted plot and the normal Q-Q plot of residuals close to linear.


* Write down the mathematical multiple regression model for this situation, defining all appropriate
parameters.

```{r c3, echo=FALSE}
#Fitting the regression using all variables
coefficients(surg.lm1)
```

\[\hat{survival} = -1179.1888797 + 86.6437068blood + 8.5012606prognosis  + 11.1245627enzyme 
\]
\[    + 38.5068155liver - 0.2201138age - 0.2201138 gender
\]

* Write down the Hypotheses for the Overall ANOVA test of multiple regression.
\
&nbsp;
\[H_0:   \beta_{1} = \beta_{2} = \beta_{3} = \beta_{4} = \beta_{5} = 0;
\]
\[H_1: \beta_{i} \neq 0 \quad\text{for at least one i (not all } \beta_{i} \quad\text{parameters are zero)}
\]

* Produce an ANOVA table for the overall multiple regression model (One combined regression SS source is sufficient).
\
&nbsp;

```{r anova, echo=FALSE}
#ANOVA table for all variables
anova(surg.lm1)
```

* Compute the F statistic for this test.
\
&nbsp;
\[
Full RegSS = RegSS_{blood} + RegSS_{prognosis \mid blood} + RegSS_{enzyme\mid blood \& prognosis} 
\]
\[
\quad + RegSS_{liver|blood\&prognosis\&enzyme} + RegSS_{age|blood\&prognosis\&enzyme\&liver}
\]
\[
\quad + RegSS_{gender|blood\&prognosis\&enzyme\&liver\&age}
\]

$\quad Full RegSS = 1005152 + 1278496 + 3442172 + 57862 + 33032 + 1 = 5816715$
\
&nbsp;
\
&nbsp;
$RegMS = \frac{RegSS}{k} = \frac{5816715}{6} = 969452.5$
\
&nbsp;
\
&nbsp;
$\text{Test statistic:}\quad  F_{obs} = \frac{RegMS}{ResMS} = \frac{969452.5}{54315} = 17.84871$
\
&nbsp;

* State the Null distribution.

\[
H_0:   \beta_{blood} = \beta_{prognosis} = \beta_{enzyme} = \beta_{liver} = \beta_{age} = \beta_{gender} = 0;
\]
\[
H_1: \text{not all}\quad \beta_{i} = 0
\]

* Compute the P-Value
```{r p_value, echo=FALSE}
#compute P-value from F-statistic
pf(17.84871, 6, 47, lower.tail = FALSE)
```
\
&nbsp;
$\text{P-Value:}\quad P(F_{6,47} >= 17.84871) = 1.190218e-10 < 0.05$

* State your conclusion (both statistical conclusion and contextual conclusion).
\
&nbsp;
P-value is 1.190218e-10. As P-value < 0.05, reject $H_0$.

* There is a significant linear relationship between survival and at least one of the five predictor variables.
\
&nbsp;

d. Using model selection procedures discussed in the course, find the best multiple regression model that
explains the data.
```{r lm1, echo=FALSE}
summary(surg.lm1)
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __gender__  P-value = 0.997413
\
&nbsp;

```{r lm2, echo=FALSE}
surg.lm2 = lm(survival ~ blood  + prognosis  + enzyme  + liver + age, data = surg.new)
summary(surg.lm2)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __liver__ P-value = 0.437595 
\
&nbsp;

```{r lm3, echo=FALSE}
surg.lm3 = lm(survival ~ blood  + prognosis  + enzyme + age, data = surg.new)
summary(surg.lm3)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __age__ P-value = 0.298    
\
&nbsp;
```{r lm4, echo=FALSE}
surg.lm4 = lm(survival ~ blood  + prognosis  + enzyme, data = surg.new)
summary(surg.lm4)
```
All predictors are significant and $R^2$ = 0.6652
\
&nbsp;
* Finallized fitted equation:
\
&nbsp;
\[\hat{survival} = -1410.846901 + 101.053887blood + 9.381966prognosis  + 12.127807enzyme 
\]
\
&nbsp;
\
&nbsp;
e. Validate your final model and comment why it is not appropriate to use the multiple regression model
to explain the survival time.
\
&nbsp;

```{r validate1, echo=FALSE}
#Check diagnostics
par(mfrow = c(1, 2))
plot(surg.lm4, which = 1:2)
#Check residuals against predictors
#(mfrow = c(1, 3))
#plot(resid(surg.lm4) ~ blood + prognosis  + enzyme, data = surg.new)
```
\
&nbsp;
\quad From above picture show the residual vs fitted plot and the normal Q-Q plot for the final model of the survival response. 
The linearity of the points in the normal Q-Q plot suggests that the data are close to normally distributed. 
However, the residuals vs fitted plot has a pattern.
This is the reason why this final model is not appropriate to use the multiple regression model to explain the survival time.
In this case, In this transformation the response variable is needed.

\
&nbsp;
f. Re-fit the model using log(survival) as the new response variable. In your answer,

* Use the model selection procedure discussed in the course starting with log(survival) as the
response and start with all the predictors.

```{r log lm1, echo=FALSE}
#Adding in the log transformed variables.
surg.new$logsurvival = log(surg.new$survival)

#Fitting the regression on the log transformed predictors.
surglog.lm1 = lm(logsurvival ~ blood + prognosis + enzyme + liver + age + gender, data = surg.new)
summary(surglog.lm1)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __liver__ P-value = 0.95503
\
&nbsp;

```{r log lm2, echo=FALSE}
surglog.lm2 = lm(logsurvival ~ blood + prognosis + enzyme + age + gender, data = surg.new)
summary(surglog.lm2)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __gender__ P-value = 0.3472615
\
&nbsp;

```{r log lm3, echo=FALSE}
surglog.lm3 = lm(logsurvival ~ blood + prognosis + enzyme + age, data = surg.new)
summary(surglog.lm3)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove __age__ P-value = 0.1232646
\
&nbsp;

```{r log lm4, echo=FALSE}
surglog.lm4 = lm(logsurvival ~ blood + prognosis + enzyme, data = surg.new)
summary(surglog.lm4)
```
All predictors are significant 
and $R^2$ = 0.7427 which is better than the model with the survival response variable.
\
&nbsp;
* Finallized fitted equation:
\
&nbsp;
\[\hat{log(survival)} = -3.76644097 + 0.09547451blood + 0.01334404prognosis  + 0.01644450enzyme 
\]
\
&nbsp;
\
&nbsp;
g. Validate your final model with the log(survival) response. In particular, in your answer,

```{r validatelog1, echo=FALSE}
par(mfrow = c(1, 2))
plot(surglog.lm4, which = 1:2)
par(mfrow = c(1, 3))
plot(resid(surglog.lm4) ~ blood + prognosis + enzyme, data = surg.new)
```
\
&nbsp;

\quad * The residuals vs fitted plot shows some pattern in but not significant.

\quad * There is slight curvature in the normal quantile plot of residuals, the data are close to normally distributed. 

\quad * No sign of curvature in the residuals against predictors plots.
\
&nbsp;

* Explain why the regression model with log(survival) response variable is superior to the model
with the survival response variable
\
&nbsp;
\quad From above picture show the residual vs fitted plot and the normal Q-Q plot for the log(survival) response.
Comparing with the final model of the survival response, the normality assumption within the log(survival) model
is better as there is some pattern but not significant in the residuals vs fitted plot and the normal Q-Q plot is close to normally distributed.
It clarifies the reason why log(survival) is superior to the other response.
\
&nbsp;


## Question 2

A car manufacturer wants to study the fuel efficiency of a new car engine. It wishes to account for any
differences between the driver and production variation. The manufacturer randomly selects 5 cars from the
production line and recruits 4 different test drivers.

| || |
| --- | --- |
| kmL | The observed efficiency of the car in km/L over a standard course |
| car | The specific car (labelled 1, 2, 3, 4 or 5) |
| driver | The driver of the car (labelled A, B, C, D) |


a. For this study, is the design balanced or unbalanced? Explain why.
```{r kml_a, echo=FALSE}
with(kml, table(driver, car))
```
\
&nbsp;
This is a balanced design because there is the same no. of replicates for each treatment combinations.
\
&nbsp;
\
&nbsp;
b. Construct two different preliminary graphs that investigate different features of the data and comment.
\
&nbsp;
```{r kml_b1, echo=FALSE}
with(kml, interaction.plot(driver, car, kmL))
#with(kml, interaction.plot(car, driver, kmL))
```
\
&nbsp;
As the lines are not parallel, interaction could be there.
\
&nbsp;

```{r kml_b2, echo=FALSE}
#par(mfrow = c(1, 2))
#boxplot(kmL  ~ driver, data = kml)
#boxplot(kmL  ~ car, data = kml)
ggplot(data = kml, aes(x=driver, y=kmL)) + geom_boxplot(aes(fill=car))
```


Overall, there are different variation among each group.
\
&nbsp;
  * Similar spread for drive A, C and D groups
\
&nbsp;
  * Combination of drive B have higher kmL than others.
\
&nbsp;
  * Groups of driver A and car-one and car-three have the lowest kmL 
\
&nbsp;
\
&nbsp;
c. Analyse the data, stating null and alternative hypothesis for each test, and check assumptions.


```{r kml_c1, echo=FALSE}
#Two-way ANOVA with interaction effect
anova.kml1 <- aov(kmL ~ driver * car, data = kml)
summary(anova.kml1)
```
&nbsp;

Model: $Y = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon$

  where $\epsilon_{ijk}$ are $N(0, \sigma^2)$ random variables
  
$\mu:$ overall population mean

$\alpha_i:$ main effect on driver

$\beta_j:$ main effect on car

$\gamma_{ij}:$ interaction effect between driver and car

$\epsilon:$ error term

  
Hypotheses $\quad H_0:   \gamma_{ij} = 0 \quad\text{against} \quad H_1: \text{at least one}\quad \gamma_{ij} \text{ non-zero}$
\
&nbsp;
Because P-value = 0.371 >  0.05, $\quad\gamma_{ij}$ is not significant.
\
&nbsp; 
No evidence to suggest that the two factors (driver and car) are not independent.
\
&nbsp;
As interaction is not significant, re-fit the model with main effects only.

&nbsp;
```{r kml_c2, echo=FALSE}
#Two-way ANOVA
anova.kml2 <- aov(kmL ~ driver + car, data = kml)
summary(anova.kml2)
```
\
&nbsp;
__Main Effects: Driver__
\
&nbsp;
Model: $y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon$

\quad Hypotheses : $\quad H_0: \alpha_i = 0 \quad\text{against} \quad H_1: \text{at least one} \quad \alpha_i \text{ non-zero }$

\quad P-Value <2e-16, less than 0.05, reject H0
\
&nbsp;
\quad Driver type is significant.
\
&nbsp;

__Main Effects: Car__
\
&nbsp;
Model: $y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon$

\quad Hypotheses : $\quad H_0: \beta_j = 0 \quad\text{against} \quad H_1: \text{at least one} \quad \beta_j \text{ non-zero }$

\quad P-Value <2e-16, less than 0.05, reject H0
\
&nbsp;
\quad Car type is significant.
\
&nbsp;
\quad Both the driver and car effects are highly significant (P-Value < 0.001)
&nbsp;

__Coefficients table:__

```{r kml lm, echo=FALSE}
kml.lm = lm(kmL ~ driver + car, data = kml)
summary(kml.lm)$coefficients
```
From the coefficients table, the effect of car-one and car-three are to reduce kml by 0.41983 and 0.86623 respectively, 
although the other variables are increase kml.
\
&nbsp;
```{r kml_c3, echo=FALSE}
par(mfrow = c(1, 2))
plot(anova.kml2, 1:2)

```
\
&nbsp;

* Residuals vs Fitted plot shows a negligible pattern, variability among residuals vs fitted is not constant.
There are several outliers, with residuals close to 0.4.

* The normal Q-Q plot of residuals follows a linear trend, residuals look close to normally distributed.
\
&nbsp;

d. State your conclusions about the effect of driver and car on the efficiency kmL. These conclusions are
only required to be at the qualitative level and can be based off the outcomes of the hypothesis tests in
c. and the preliminary plots in b. You do not need to statistically examine the multiple comparisons between contrasts and interactions.
\
&nbsp;
\quad From the above findings, we can say that both null hypotheses of the main effects (driver and car) are rejected. 
Moreover, the normal Q-Q plot follows a linear trend and residual plots have no pattern, suggesting the linear model adequately.
From this, we can conclude that the efficiency of the car in km/L depend upon the factors test driver and cars.
\
&nbsp;
