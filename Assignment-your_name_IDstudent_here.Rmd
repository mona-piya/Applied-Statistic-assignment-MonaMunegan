---
title: "Piyakorn Munegan (Mona) StudentID: 46318461"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
surg=read.table('data/surg.dat', header = TRUE)
kml=read.table('data/kml.dat', header = TRUE)
```

```{r load-packages, include=FALSE}
library(ggplot2)
library(ggcorrplot)
```
# Assignment Semester 1
## Question 1

A medical research team wants to investigate the survival time of patients that have a particular type of liver
operation as part of their treatment. For each patient in the study, the following variables were recorded:

| || |
| --- | --- |
| blood | Blood clotting Index |
| prognosis | Prognosis Index |
| enzyme | Enzyme function Index |
| liver | Liver function Index |
| age | Age of the patient, in years |
| gender | Gender of the patient, (Male of Female) |
| survival | Survival time of the patient after surgery (in days) |


a. Produce a scatterplot of the data and comment on the features of the data and possible relationships
between the response and predictors and relationships between the predictors themselves.

```{r corr, echo=FALSE}
surg.cor <- data.frame(surg)
surg.cor$gender <- NULL
#head(surg.new)
```

&nbsp;

```{r scatterplot, echo=FALSE}
plot(surg.cor)
```

There are moderate correlation between survival and enzyme and liver. Slight correlation between survival and prognosis.
\
&nbsp;
\
&nbsp;
Why it is necessary to remove the gender variable to compute the correlation matrix?

Because the gender variable is a categorical variables. To compute the correlation matrix, every variables must be numeric.

&nbsp;
b. Compute the correlation matrix of the dataset and comment.
&nbsp;
```{r corrmatrix, echo=FALSE}
corr <- round(cor(surg.cor), 2)
corr
#ggcorrplot(corr, outline.col = "white", lab = TRUE, lab_size = 4, tl.cex=12, legend.title = "Correlation")
```
\
&nbsp;
The correlation matrix shows that there are moderately correlated between survival and liver(0.67) and enzyme(0.58).
Low correlation between survival and blood(0.35) and prognosis(0.42). The correlation between survival and age is -0.12, 
which is close to 0, indicates that no linear relationship between these variables.
\
&nbsp;
c. Fit a model using all the predictors to explain the survival response

```{r c1, echo=FALSE}
surg.new <- data.frame(surg)
#Transforming Gender to numerical variable
surg.new$gender[surg$gender=="M"] <- 1
surg.new$gender[surg$gender=="F"] <- 0
surg.new$gender <- as.integer(surg.new$gender)
```

```{r c2, echo=FALSE}
#Fitting linear model with original data
surg.lm1 = lm(survival ~ blood  + prognosis  + enzyme  + liver + age + gender, data = surg.new)
par(mfrow = c(1, 2))
plot(surg.lm1, which=1:2)
```
\
&nbsp;
5 and 28 are significant outliers, need to be remove.
\
&nbsp;

* Produce an ANOVA table for the overall multiple regression model (One combined regression SS source is sufficient).

```{r c3, echo=FALSE}
#clean the outlier
surg.new = surg.new[-c(5, 28),]
#Fitting linear model with cleaned data
surg.lm1 = lm(survival ~ blood  + prognosis  + enzyme  + liver + age + gender, data = surg.new)
par(mfrow = c(1, 2))
plot(surg.lm1, which=1:2)
```
\
&nbsp;
After cleaning outliers....
\
&nbsp;
```{r c4, echo=FALSE}
#Fitting the regression using all variables
surg.lm1 = lm(survival ~ blood  + prognosis  + enzyme  + liver + age + gender, data = surg.new)
coefficients(surg.lm1)
```

* Write down the mathematical multiple regression model for this situation, defining all appropriate
parameters.
\
&nbsp;
\[\hat{survival} = -595.240879 + 31.568219blood + 8.059842prognosis  + 8.087624enzyme 
\]
\[    + 31.028299liver - 2.316786age - 42.186475gender
\]

* Write down the Hypotheses for the Overall ANOVA test of multiple regression.
\
&nbsp;
\[H_0:   \beta_{1} = \beta_{2} = ... = \beta_{k} = 0;
\]
\[H_1: \beta_{i} \neq 0 \quad\text{for at least one i (not all } \beta_{i} \quad\text{parameters are zero)}
\]

* Produce an ANOVA table for the overall multiple regression model (One combined regression SS source is sufficient).
\
&nbsp;

```{r anova, echo=FALSE}
#ANOVA table for all variables
anova(surg.lm1)
```
\
&nbsp;
\
&nbsp;

* Compute the F statistic for this test.
\
&nbsp;
\[
Full RegSS = RegSS_{blood} + RegSS_{prognosis \mid blood} + RegSS_{enzyme\mid blood \& prognosis} 
\]
\[
              \quad + RegSS_{liver|blood\&prognosis\&enzyme} + RegSS_{age|blood\&prognosis\&enzyme\&liver} + RegSS_{gender|blood\&prognosis\&enzyme\&liver\&age}
\]
$Full RegSS = 12670 + 1118269 + 1692481 + 58863 + 28117 + 20450 = 2930850$
\
&nbsp;
\
&nbsp;
$RegMS = \frac{RegSS}{k} = \frac{2930850}{6} = 488475$
\
&nbsp;
\
&nbsp;
$\text{Test statistic:}\quad  F_{obs} = \frac{RegMS}{ResMS} = \frac{488475}{21978} = 22.22563$
\
&nbsp;

* State the Null distribution.
\
&nbsp;
\[
H_0:   \beta_{blood} = \beta_{prognosis} = \beta_{enzyme} = \beta_{liver} = \beta_{age} = \beta_{gender} = 0;
\]
\[
H_1: \text{not all}\quad \beta_{i} = 0
\]

* Compute the P-Value
```{r p_value, echo=FALSE}
#compute P-value from F-statistic
pf(22.22563, 6, 45, lower.tail = FALSE)
```
\
&nbsp;
$\text{P-Value:}\quad P(F_{6,45} >= 22.22563) = 5.788194e-12 < 0.05$

* State your conclusion (both statistical conclusion and contextual conclusion).
\
&nbsp;
P-value is 5.788194e-12, Reject H0.

* There is a significant linear relationship between survival and at least one of the five predictor variables.
\
&nbsp;

d. Using model selection procedures discussed in the course, find the best multiple regression model that
explains the data.
```{r lm1, echo=FALSE}
summary(surg.lm1)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove liver P-value = 0.35255
\
&nbsp;

```{r lm2, echo=FALSE}
surg.lm2 = lm(survival ~ blood  + prognosis  + enzyme + age + gender, data = surg.new)
summary(surg.lm2)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove gender P-value = 0.21426
\
&nbsp;

```{r lm3, echo=FALSE}
surg.lm3 = lm(survival ~ blood  + prognosis  + enzyme + age, data = surg.new)
summary(surg.lm3)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove age P-value = 0.128046
\
&nbsp;
```{r lm4, echo=FALSE}
surg.lm4 = lm(survival ~ blood  + prognosis  + enzyme, data = surg.new)
summary(surg.lm4)$coefficients
```

\
&nbsp;
e. Validate your final model and comment why it is not appropriate to use the multiple regression model
to explain the survival time.
\
&nbsp;

```{r validate1, echo=FALSE}
#Check diagnostics
par(mfrow = c(1, 2))
plot(surg.lm4, which = 1:2)
#Check residuals against predictors
par(mfrow = c(1, 3))
plot(resid(surg.lm4) ~ blood + prognosis  + enzyme, data = surg.new)
```
\
&nbsp;
For the final model(surg.lm4):
\
&nbsp;
1. The Normal Q-Q plot of residuals has slight curvature but close to normally distributed. ???
\
&nbsp;
2. The residuals vs fitted shows fan pattern. ???
\
&nbsp;
3. Residuals vs predictor plots ???
\
&nbsp;
So Transform response....
\
&nbsp;

### Transformation

f. Re-fit the model using log(survival) as the new response variable. In your answer,
* Use the model selection procedure discussed in the course starting with log(survival) as the
response and start with all the predictors.

```{r log lm1, echo=FALSE}
#Adding in the log transformed variables.
surg.new$logsurvival = log(surg.new$survival)

#Fitting the regression on the log transformed predictors.
surglog.lm1 = lm(logsurvival ~ blood + prognosis + enzyme + liver + age + gender, data = surg.new)
summary(surglog.lm1)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove liver P-value = 0.8832
\
&nbsp;

```{r log lm2, echo=FALSE}
surglog.lm2 = lm(logsurvival ~ blood + prognosis + enzyme + age + gender, data = surg.new)
summary(surglog.lm2)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove gender P-value = 0.2023
\
&nbsp;

```{r log lm3, echo=FALSE}
surglog.lm3 = lm(logsurvival ~ blood + prognosis + enzyme + age, data = surg.new)
summary(surglog.lm3)$coefficients
```
\
&nbsp;
Removing one none significant variable (if there are many none significant vars, pick the largest P-value).
Remove age P-value = 0.1034
\
&nbsp;

```{r log lm4, echo=FALSE}
surglog.lm4 = lm(logsurvival ~ blood + prognosis + enzyme, data = surg.new)
summary(surglog.lm4)$coefficients
```
\
&nbsp;
g. Validate your final model with the log(survival) response. In particular, in your answer,

\
&nbsp;
```{r validatelog1, echo=FALSE}
par(mfrow = c(1, 2))
plot(surglog.lm4, which = 1:2)
par(mfrow = c(1, 3))
plot(resid(surglog.lm4) ~ blood + prognosis + enzyme, data = surg.new)
```
\
&nbsp;

* Explain why the regression model with log(survival) response variable is superior to the model
with the survival response variable
\
The residuals vs fitted looks better for the log transformed response.?????

\
&nbsp;


## Question 2

A car manufacturer wants to study the fuel efficiency of a new car engine. It wishes to account for any
differences between the driver and production variation. The manufacturer randomly selects 5 cars from the
production line and recruits 4 different test drivers.

| || |
| --- | --- |
| kmL | The observed efficiency of the car in km/L over a standard course |
| car | The specific car (labelled 1, 2, 3, 4 or 5) |
| driver | The driver of the car (labelled A, B, C, D) |


a. For this study, is the design balanced or unbalanced? Explain why.
```{r kml_a, echo=FALSE}
with(kml, table(driver, car))
```
This is a balanced design because there is the same no. of replicates for each treatment combinations.

b. Construct two different preliminary graphs that investigate different features of the data and comment.
&nbsp;
```{r kml_b1, echo=FALSE}
with(kml, interaction.plot(driver, car, kmL))
#with(kml, interaction.plot(car, driver, kmL))
```
As the lines are not parallel, interaction could be there.

&nbsp;

```{r kml_b2, echo=FALSE}
par(mfrow = c(1, 2))
boxplot(kmL  ~ driver, data = kml)
boxplot(kmL  ~ car, data = kml)
#boxplot(kmL  ~ driver + car, data = kml)

```
For the boxplots, there are similar spread for driver and car.

&nbsp;
c. Analyse the data, stating null and alternative hypothesis for each test, and check assumptions.


```{r kml_c1, echo=FALSE}
#Two-way ANOVA with interaction effect
anova.klm1 <- aov(kmL ~ driver * car, data = kml)
summary(anova.klm1)
```
&nbsp;

Model: $Y = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk}$

  where $\epsilon_{ijk}$ are $N(0, \sigma^2)$ random variables
  
$\mu:$ overall population mean

$\alpha_i:$ main effect on driver

$\beta_j:$ main effect on car

$\gamma_{ij}:$ interaction effect between driver and car

$\epsilon_{ijk}:$ error term

  
Hypotheses $\quad H_0:   \gamma_{ij} = 0 \quad\text{against} \quad H_1: \text{at least one}\quad \gamma_{ij} \text{ non-zero}$


Because P-value = 0.371 >  0.05, $\quad\gamma_{ij}$ is not significant.
\
&nbsp; 
No evidence to suggest that the two factors (driver and car) are not independent.
\
&nbsp;
As interaction is not significant, re-fit the model with main effects only.

&nbsp;
```{r kml_c2, echo=FALSE}
#Two-way ANOVA
anova.klm2 <- aov(kmL ~ driver + car, data = kml)
summary(anova.klm2)
```

&nbsp;

Model: $y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon_{ijk}$

Hypotheses : $\quad H_0: \beta_j = 0 \quad\text{against} \quad H_1: \text{at least one} \quad \beta_j \text{ non-zero }$

Both the driver and car effects are highly significant (P-Value < 0.001)
&nbsp;

```{r kml_c3, echo=FALSE}
par(mfrow = c(1, 2))
plot(anova.klm2, 1:2)

```

* Residuals vs Fitted plot shows negligible pattern, variability among residuals vs fitted is not constant.

* The quantile plot of residuals follows a linear trend, residuals look close to normally distributed.
\
&nbsp;

d. State your conclusions about the effect of driver and car on the efficiency kmL. These conclusions are
only required to be at the qualitative level and can be based off the outcomes of the hypothesis tests in
c. and the preliminary plots in b.. 
You do not need to statistically examine the multiple comparisons between contrasts and interactions.
\
&nbsp;
The p-value for the effects of driver and car are less than the significant level 0.05,
we have evidence to reject $H_0$. 
and the quantile plot looks linear and residual plots have no pattern, suggesting linear model adequate. ????


